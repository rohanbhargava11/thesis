#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
For our sensor model to work i.e.
 assign weights to our particles we need some sort of reference.
 Some examples are Landmarks, Maps etc.
 Austin and ELizar used static maps as a reference.
 We have a side sonar on our AUVs and image generated can be used as a reference.
 The side sonar outputs pings which can be used to generate images.
 Andrew Vardy explains on how to generate images and in our algorithm we
 use it as a black box.
 The final image that is generated is shown below.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Side Sonar Image
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../visual_sonar/sonar_59/18.jpg
	lyxscale 50

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
We run feature extraction such as SURF on the image to detect interest points.
 The circle in the image shown below are the interest points.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
SURF Keypoints
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../visual_sonar/surf_working.png
	lyxscale 50

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
These interest points can be treated as landmarks.
 We use a high Hessian threshold so that we have a maximum of 4 landmarks.
 We can measure the distance of the robot and the particles from the landmark.
 Based on the measurements we assign weights to the particle.
 This method allows us independence from a static map as well as helps in
 learning the motion model on the fly in a new environment.
 
\end_layout

\end_body
\end_document
